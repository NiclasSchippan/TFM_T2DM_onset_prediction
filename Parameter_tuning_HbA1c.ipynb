{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e1b7a-e389-454f-aed2-91f89ac81303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to investigate hyperparamter configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6644b75-7fba-450e-95e0-70616b72714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, FunctionTransformer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "import torch # For building the networks \n",
    "import torchtuples as tt # Some useful functions\n",
    "from pycox.models import CoxPH\n",
    "from pycox.evaluation import EvalSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3166d5-15a1-45d7-a5d1-d4f8eaa91029",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pyreadr.read_r(\"/home/jupyter-niclas/Approach_2_Including_HbA1c_t0/Parameter_tuning/input_cox.rds\")\n",
    "# Coverting R-file as panda\n",
    "df = df_complete[None]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a18d09-8d54-48b7-9e27-1188c6e3aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using stratification to make sure the event-ratio is constant over subsets\n",
    "event_col = 'event' \n",
    "\n",
    "# First split: 80% train+val, 20% test\n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1234)\n",
    "for train_val_idx, test_idx in sss1.split(df, df[event_col]):\n",
    "    df_train_val = df.iloc[train_val_idx].reset_index(drop=True)\n",
    "    df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "# Second split: 20% of train_val becomes validation â†’ 16% of full set\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_idx, val_idx in sss2.split(df_train_val, df_train_val[event_col]):\n",
    "    df_train = df_train_val.iloc[train_idx].reset_index(drop=True)\n",
    "    df_val = df_train_val.iloc[val_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca5bcf-d1e9-499d-9690-ee3ca458d784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check event rate\n",
    "def check_event_rate(df, name):\n",
    "    rate = df[event_col].mean()\n",
    "    print(f\"{name} event rate: {rate:.3f} ({df[event_col].sum()}/{len(df)})\")\n",
    "\n",
    "check_event_rate(df_train, \"Train\")\n",
    "check_event_rate(df_val, \"Validation\")\n",
    "check_event_rate(df_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1364cca-caec-4cc5-ad62-d492062521dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformations\n",
    "cols_standardize = ['val_HbA1c', 'age', 'BMI', 'systolic_blood_pressure', 'diastolic_blood_pressure', 'cholesterol_LDL', 'triglycerides', 'ACR']\n",
    "cols_categorical = ['sexe', 'smoking_status', 'alcohol_risk_consumption', 'qmedea', 'cat_eGFR']\n",
    "\n",
    "# Standardize numeric features\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "\n",
    "# One-hot encode categorical (multi-class) features\n",
    "categorical = [([col], OneHotEncoder(sparse_output=False, handle_unknown='ignore')) for col in cols_categorical]\n",
    "\n",
    "# Combine \n",
    "x_mapper = DataFrameMapper(standardize + categorical, df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f23b1-376a-42ee-b1d0-f3997a78d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_mapper.fit_transform(df_train).to_numpy().astype('float32')\n",
    "x_val = x_mapper.transform(df_val).to_numpy().astype('float32')\n",
    "x_test = x_mapper.transform(df_test).to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf349d7-a67b-4f47-86ce-41ba0b3b7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set targets\n",
    "get_target = lambda df: (df['time_to_event'].values, df['event'].values)\n",
    "y_train = get_target(df_train)\n",
    "y_val = get_target(df_val)\n",
    "durations_test, events_test = get_target(df_test)\n",
    "val = x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca86be-3352-4fcd-9c16-2f793a62e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes these variables are defined already:\n",
    "# x_train, y_train, x_val, y_val, x_test, durations_test, events_test\n",
    "\n",
    "# Define grid\n",
    "param_grid = {\n",
    "    'num_nodes': [[32], [64], [64, 32]],\n",
    "    'dropout': [0.0, 0.1, 0.3],\n",
    "    'batch_size': [128, 256],\n",
    "    'learning_rate': [1e-3, 1e-4],\n",
    "    'batch_norm': [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34daefa4-b46b-4384-90b9-34f62065c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = list(ParameterGrid(param_grid))\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(grid):\n",
    "    print(f\"\\n Running configuration {i+1}/{len(grid)}: {params}\")\n",
    "    \n",
    "    # Build model\n",
    "    net = tt.practical.MLPVanilla(\n",
    "        in_features=x_train.shape[1],\n",
    "        num_nodes=params['num_nodes'],\n",
    "        out_features=1,\n",
    "        batch_norm=params['batch_norm'],\n",
    "        dropout=params['dropout'],\n",
    "        activation=torch.nn.ReLU\n",
    "    )\n",
    " \n",
    "    model = CoxPH(net, tt.optim.Adam)\n",
    "    model.optimizer.set_lr(params['learning_rate'])\n",
    "    \n",
    "    # Fit model\n",
    "    callbacks = [tt.callbacks.EarlyStopping(patience=10)]\n",
    "    log = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=256,\n",
    "        callbacks=callbacks,\n",
    "        verbose=False,\n",
    "        val_data=(x_val, y_val),\n",
    "        val_batch_size=params['batch_size']\n",
    "    )\n",
    "\n",
    "    model.compute_baseline_hazards()\n",
    "    \n",
    "    # Evaluate: Train\n",
    "    surv_train = model.predict_surv_df(x_train)\n",
    "    ev_train = EvalSurv(surv_train, y_train[0], y_train[1], censor_surv='km')\n",
    "    c_train = ev_train.concordance_td()\n",
    "\n",
    "    # Evaluate: Validation\n",
    "    surv_val = model.predict_surv_df(x_val)\n",
    "    ev_val = EvalSurv(surv_val, y_val[0], y_val[1], censor_surv='km')\n",
    "    c_val = ev_val.concordance_td()\n",
    "\n",
    "    # Evaluate: Test\n",
    "    surv_test = model.predict_surv_df(x_test)\n",
    "    ev_test = EvalSurv(surv_test, durations_test, events_test, censor_surv='km')\n",
    "    c_test = ev_test.concordance_td()\n",
    "    \n",
    "    # Overfitting indicator\n",
    "    overfit_gap = c_train - c_val\n",
    "\n",
    "    print(f\"C-index | Train: {c_train:.4f} | Val: {c_val:.4f} | Test: {c_test:.4f} | Gap: {overfit_gap:.4f}\")\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        **params,\n",
    "        'c_index_train': c_train,\n",
    "        'c_index_val': c_val,\n",
    "        'c_index_test': c_test,\n",
    "        'overfit_gap': overfit_gap\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc3f9a-32ea-4e50-a4bf-47da7564e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show results\n",
    "results_df = pd.DataFrame(results).sort_values(by='c_index_val', ascending=False)\n",
    "from IPython.display import display\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5884444d-1185-4896-a47e-7fc1b7db7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame as CSV\n",
    "results_df.to_csv(\"Deep_Cox_parameter_tuning_copy_#1_results.csv\", index=False)\n",
    "print(\"Results saved as: Deep_Cox_parameter_tuning_copy_#1_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31c3bd-48da-45cf-94f3-cc624c9e7c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['config'] = results_df.apply(lambda row: \n",
    "    f\"LR:{row['learning_rate']},BS:{row['batch_size']},DO:{row['dropout']},NN:{row['num_nodes']}\", axis=1\n",
    ")\n",
    "\n",
    "# Sort configs by validation C-index (descending)\n",
    "results_df = results_df.sort_values(by='c_index_val', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# --- Step 3: Plot C-index scores ---\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(results_df['config'], results_df['c_index_train'], marker='^', label='Train C-index', linestyle='-')\n",
    "plt.plot(results_df['config'], results_df['c_index_val'], marker='o', label='Validation C-index', linestyle='--')\n",
    "plt.plot(results_df['config'], results_df['c_index_test'], marker='s', label='Test C-index', linestyle='-.')\n",
    "\n",
    "plt.ylabel(\"C-index\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Deep_Cox_copy_param_search_plot.jpg\", dpi=300)\n",
    "print(\"Plot saved as: Deep_Cox_copy_param_search_plot.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9cbcec-7b30-4659-b628-cf8b2da8ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_df = results_df.sort_values(by='c_index_val', ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(top10_df['config'], top10_df['c_index_train'], marker='^', label='Train C-index', linestyle='-')\n",
    "plt.plot(top10_df['config'], top10_df['c_index_val'], marker='o', label='Validation C-index', linestyle='--')\n",
    "plt.plot(top10_df['config'], top10_df['c_index_test'], marker='s', label='Test C-index', linestyle='-.')\n",
    "\n",
    "plt.ylabel(\"C-index\", fontsize=18)\n",
    "plt.xticks([]) \n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "# Horizontal legend below the plot\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=3, frameon=False, fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Deep_Cox_top10_param_search_plot.jpg\", dpi=300, bbox_inches='tight')\n",
    "print(\"Plot saved as: Deep_Cox_top10_param_search_plot.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908807d8-c5b6-4606-baec-71cb4f29f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter testing #2: focus on layer-depth\n",
    "# Define the range of architectures to test\n",
    "layer_configs = [\n",
    "    [32],\n",
    "    [64],\n",
    "    [128],\n",
    "    [64, 32],\n",
    "    [128, 64],\n",
    "    [128, 64, 32],\n",
    "    [256, 128, 64]\n",
    "]\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25e851-c4ec-42fa-a499-1710455ed8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed hyperparams\n",
    "fixed_dropout = 0.3\n",
    "fixed_batch_size = 128\n",
    "fixed_learning_rate = 1e-3\n",
    "fixed_batch_norm = True\n",
    "\n",
    "for i, num_nodes in enumerate(layer_configs):\n",
    "    print(f\"\\n Running config {i+1}/{len(layer_configs)}: Layers {num_nodes}\")\n",
    "    \n",
    "    # Model setup\n",
    "    net = tt.practical.MLPVanilla(\n",
    "        in_features=x_train.shape[1],\n",
    "        num_nodes=num_nodes,\n",
    "        out_features=1,\n",
    "        batch_norm=fixed_batch_norm,\n",
    "        dropout=fixed_dropout,\n",
    "        activation=torch.nn.ReLU\n",
    "    )\n",
    "    \n",
    "    model = CoxPH(net, tt.optim.Adam)\n",
    "    model.optimizer.set_lr(fixed_learning_rate)\n",
    "    \n",
    "    # Train\n",
    "    callbacks = [tt.callbacks.EarlyStopping(patience=10)]\n",
    "    log = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=fixed_batch_size,\n",
    "        epochs=256,\n",
    "        callbacks=callbacks,\n",
    "        verbose=False,\n",
    "        val_data=(x_val, y_val),\n",
    "        val_batch_size=fixed_batch_size\n",
    "    )\n",
    "    \n",
    "    model.compute_baseline_hazards()\n",
    "    \n",
    "    # Evaluation\n",
    "    ev_train = EvalSurv(model.predict_surv_df(x_train), y_train[0], y_train[1], censor_surv='km')\n",
    "    c_train = ev_train.concordance_td()\n",
    "    \n",
    "    ev_val = EvalSurv(model.predict_surv_df(x_val), y_val[0], y_val[1], censor_surv='km')\n",
    "    c_val = ev_val.concordance_td()\n",
    "    \n",
    "    ev_test = EvalSurv(model.predict_surv_df(x_test), durations_test, events_test, censor_surv='km')\n",
    "    c_test = ev_test.concordance_td()\n",
    "    \n",
    "    overfit_gap = c_train - c_val\n",
    "    \n",
    "    print(f\" C-index | Train: {c_train:.4f} | Val: {c_val:.4f} | Test: {c_test:.4f} | Gap: {overfit_gap:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'num_nodes': str(num_nodes),\n",
    "        'c_index_train': c_train,\n",
    "        'c_index_val': c_val,\n",
    "        'c_index_test': c_test,\n",
    "        'overfit_gap': overfit_gap\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813abb15-04cd-4ed0-9b5d-52033eb7d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and show results\n",
    "results_df = pd.DataFrame(results).sort_values(by='c_index_val', ascending=False)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87c26-19be-4f32-b71c-fcf27f3eeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame as CSV\n",
    "results_df.to_csv(\"Deep_Cox_parameter_tuning_copy_#2_layer_depth_results.csv\", index=False)\n",
    "print(\"Results saved as: Deep_Cox_parameter_tuning_copy_#2_layer_depth_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30529a-829c-40de-a08e-bbd54dc35e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot C-index (val and test) vs layer configuration\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_labels = results_df['num_nodes']\n",
    "\n",
    "plt.plot(x_labels, results_df['c_index_val'], marker='o', label='Validation C-index')\n",
    "plt.plot(x_labels, results_df['c_index_test'], marker='s', label='Test C-index')\n",
    "plt.plot(x_labels, results_df['c_index_train'], marker='^', label='Train C-index')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Layer Configuration (num_nodes)\")\n",
    "plt.ylabel(\"C-index\")\n",
    "plt.title(\"C-index vs. Network Depth\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Deep_Cox_layer_depth_test_plot.jpg\", dpi=300)\n",
    "print(\"Plot saved as: Deep_Cox_layer_depth_test_plot.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad9e45-c5a7-40b3-84b9-c42b9abf7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter testing #3\n",
    "# Define architectural parameter grid\n",
    "param_grid = {\n",
    "    'layer_config': [[32], [64], [64, 32], [64, 64], [128, 64]],\n",
    "    'activation': [torch.nn.ReLU, torch.nn.ELU, torch.nn.Tanh],\n",
    "    'batch_norm': [True, False]\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "results = []\n",
    "\n",
    "# Fixed parameters from previous tuning\n",
    "learning_rate = 1e-3\n",
    "batch_size = 128\n",
    "dropout = 0.3\n",
    "\n",
    "for i, params in enumerate(grid):\n",
    "    print(f\"\\n Running architecture configuration {i+1}/{len(grid)}: {params}\")\n",
    "\n",
    "    # Build model\n",
    "    net = tt.practical.MLPVanilla(\n",
    "        in_features=x_train.shape[1],\n",
    "        num_nodes=params['layer_config'],\n",
    "        out_features=1,\n",
    "        batch_norm=params['batch_norm'],\n",
    "        dropout=dropout,\n",
    "        activation=params['activation']\n",
    "    )\n",
    "\n",
    "    model = CoxPH(net, tt.optim.Adam)\n",
    "    model.optimizer.set_lr(learning_rate)\n",
    "\n",
    "    # Fit model\n",
    "    callbacks = [tt.callbacks.EarlyStopping(patience=10)]\n",
    "    log = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=256,\n",
    "        callbacks=callbacks,\n",
    "        verbose=False,\n",
    "        val_data=(x_val, y_val),\n",
    "        val_batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    model.compute_baseline_hazards()\n",
    "\n",
    "    # Evaluate: Train\n",
    "    surv_train = model.predict_surv_df(x_train)\n",
    "    ev_train = EvalSurv(surv_train, y_train[0], y_train[1], censor_surv='km')\n",
    "    c_train = ev_train.concordance_td()\n",
    "\n",
    "    # Evaluate: Validation\n",
    "    surv_val = model.predict_surv_df(x_val)\n",
    "    ev_val = EvalSurv(surv_val, y_val[0], y_val[1], censor_surv='km')\n",
    "    c_val = ev_val.concordance_td()\n",
    "\n",
    "    # Evaluate: Test\n",
    "    surv_test = model.predict_surv_df(x_test)\n",
    "    ev_test = EvalSurv(surv_test, durations_test, events_test, censor_surv='km')\n",
    "    c_test = ev_test.concordance_td()\n",
    "\n",
    "    overfit_gap = c_train - c_val\n",
    "\n",
    "    print(f\"C-index | Train: {c_train:.4f} | Val: {c_val:.4f} | Test: {c_test:.4f} | Gap: {overfit_gap:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        'layer_config': params['layer_config'],\n",
    "        'activation': params['activation'].__name__,\n",
    "        'batch_norm': params['batch_norm'],\n",
    "        'c_index_train': c_train,\n",
    "        'c_index_val': c_val,\n",
    "        'c_index_test': c_test,\n",
    "        'overfit_gap': overfit_gap\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6a0e6-a27c-4a46-8400-b56be5a7ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and sort\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['config'] = results_df.apply(lambda row: \n",
    "    f\"L:{row['layer_config']},A:{row['activation']},BN:{row['batch_norm']}\", axis=1)\n",
    "results_df = results_df.sort_values(by='c_index_val', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display and save\n",
    "from IPython.display import display\n",
    "display(results_df)\n",
    "results_df.to_csv(\"Deep_Cox_architecture_analysis_results.csv\", index=False)\n",
    "print(\"Results saved as: Deep_Cox_architecture_analysis_results.csv\")\n",
    "\n",
    "# Plot C-index scores for top 10 configs\n",
    "top10_df = results_df.sort_values(by='c_index_val', ascending=False).head(10).reset_index(drop=True)\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.plot(top10_df['config'], top10_df['c_index_train'], marker='^', label='Train C-index', linestyle='-')\n",
    "plt.plot(top10_df['config'], top10_df['c_index_val'], marker='o', label='Validation C-index', linestyle='--')\n",
    "plt.plot(top10_df['config'], top10_df['c_index_test'], marker='s', label='Test C-index', linestyle='-.')\n",
    "\n",
    "plt.ylabel(\"C-index\", fontsize=18)\n",
    "plt.xticks([]) \n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "# Horizontal legend below the plot\n",
    "plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=3, frameon=False, fontsize=18)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Deep_Cox_top10_architecture_analysis_plot.jpg\", dpi=300)\n",
    "print(\"Plot saved as: Deep_Cox_architecture_analysis_plot.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318c42b-3549-4791-93e3-eba76f75e6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
