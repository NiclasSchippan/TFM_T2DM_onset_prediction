{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c527a0b-a912-42d8-9d08-955486555d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to investigate feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ff630-4052-473d-9f5e-30eff7530cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lifelines import CoxPHFitter\n",
    "import featuretools as ft\n",
    "from featuretools.primitives import (\n",
    "    AddNumeric, SubtractNumeric, MultiplyNumeric, DivideNumeric,\n",
    "    Absolute, Negate, Percentile\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6774d-32c6-4d0d-a656-15eb94681c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pyreadr.read_r(\"/home/jupyter-niclas/Approach_3_Incuding_HbA1c_trend/Feature_engineering/input_cox_trend.rds\")\n",
    "# Coverting R-file as panda\n",
    "df = df_complete[None]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf61e1-4b25-49fe-b0d2-66c2ddda1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 1: INITIAL CLEAN SETUP ===\n",
    "# Load your DataFrame as df (with 'time_to_event' and 'event')\n",
    "df = df.reset_index(drop=True)\n",
    "df['id'] = df.index\n",
    "\n",
    "# Separate survival targets\n",
    "df_base = df.drop(columns=['time_to_event', 'event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4c6ae-a249-4435-b6de-e7434f75154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: CREATE ENTITYSET AND APPLY FEATURETOOLS\n",
    "es = ft.EntitySet(id=\"survival_data\")\n",
    "es = es.add_dataframe(dataframe_name=\"df\", dataframe=df_base, index=\"id\")\n",
    "\n",
    "feature_matrix, feature_defs = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_dataframe_name=\"df\",\n",
    "    max_depth=2,\n",
    "    verbose=True,\n",
    "    trans_primitives=[\n",
    "        AddNumeric(), SubtractNumeric(), MultiplyNumeric(), DivideNumeric(),\n",
    "        Absolute(), Negate(), Percentile()\n",
    "    ],\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Add survival targets back in\n",
    "feature_matrix['time_to_event'] = df['time_to_event'].values\n",
    "feature_matrix['event'] = df['event'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b9210-25d4-414a-9fbf-92336269ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: CLEAN FEATURE MATRIX\n",
    "X = feature_matrix.drop(columns=['time_to_event', 'event'])\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.dropna(axis=1, thresh=int(0.98 * len(X)))\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Prepare target vectors\n",
    "y_duration = feature_matrix['time_to_event'].values.astype('float32')\n",
    "y_event = feature_matrix['event'].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa34ee-6522-4d94-99b2-546215e41807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: SPLIT THE DATA\n",
    "X_train, X_temp, y_dur_train, y_dur_temp, y_evt_train, y_evt_temp = train_test_split(\n",
    "    X, y_duration, y_event, test_size=0.4, random_state=42, stratify=y_event)\n",
    "X_val, X_test, y_dur_val, y_dur_test, y_evt_val, y_evt_test = train_test_split(\n",
    "    X_temp, y_dur_temp, y_evt_temp, test_size=0.5, random_state=1234, stratify=y_evt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c5be0-c040-4e80-a21c-95fa6be33aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: FEATURE SELECTION & SCALING\n",
    "vt = VarianceThreshold(threshold=0.01)\n",
    "X_train_vt = vt.fit_transform(X_train)\n",
    "X_val_vt = vt.transform(X_val)\n",
    "X_test_vt = vt.transform(X_test)\n",
    "\n",
    "vt_feature_names = X.columns[vt.get_support()]\n",
    "selector = SelectKBest(score_func=f_regression, k=50)\n",
    "X_train_selected = selector.fit_transform(X_train_vt, y_dur_train)\n",
    "X_val_selected = selector.transform(X_val_vt)\n",
    "X_test_selected = selector.transform(X_test_vt)\n",
    "\n",
    "selected_feature_names = vt_feature_names[selector.get_support()]\n",
    "\n",
    "# Scale the selected features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected).astype('float32')\n",
    "X_val_scaled = scaler.transform(X_val_selected).astype('float32')\n",
    "X_test_scaled = scaler.transform(X_test_selected).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdabe1a3-3c2f-4204-a1b3-64f2bd36c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 6: LIFELINES COXPH BASELINE (WITHOUT FEATURE ENGINEERING) ===\n",
    "X_train_base = pd.DataFrame(X_train_scaled, columns=selected_feature_names)\n",
    "train_base = X_train_base.copy()\n",
    "train_base['duration'] = y_dur_train\n",
    "train_base['event'] = y_evt_train\n",
    "\n",
    "# Drop collinear features\n",
    "corr_matrix = X_train_base.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.98)]\n",
    "X_train_base_filtered = X_train_base.drop(columns=to_drop)\n",
    "\n",
    "# Rebuild and fit baseline model\n",
    "train_base_filtered = X_train_base_filtered.copy()\n",
    "train_base_filtered['duration'] = y_dur_train\n",
    "train_base_filtered['event'] = y_evt_train\n",
    "\n",
    "cph_base = CoxPHFitter(penalizer=0.1)\n",
    "cph_base.fit(train_base_filtered, duration_col='duration', event_col='event')\n",
    "cph_base.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af1325-54e8-481a-a926-7827a561eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 7: FINAL EVALUATION OF ENGINEERED FEATURES ===\n",
    "print(\"\\nTop features from engineered matrix used in final model:\")\n",
    "summary = cph_base.summary.abs().sort_values('coef', ascending=False)\n",
    "print(summary[['coef', 'p']])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "cph_base.plot(hazard_ratios=True)\n",
    "plt.title(\"Feature Effects on Hazard (HR > 1 = increased risk)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a87695-56f0-4243-a4d6-42cd76cd7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative plot\n",
    "# Sort features by coefficient\n",
    "sorted_features = cph_base.params_.sort_values(ascending=True).index  \n",
    "# Plot only those features in sorted order\n",
    "plt.figure(figsize=(10, 6))\n",
    "cph_base.plot(hazard_ratios=True, columns=sorted_features)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"engineered_feature_effects_sorted_trend.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4954af1-108e-4034-a877-8f94dde39583",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycox.models import CoxPH as PycoxCoxPH\n",
    "from pycox.evaluation import EvalSurv\n",
    "import torchtuples as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060dec20-f26c-4e7e-a431-54507ea14e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 8: TRAIN PYCOX MODEL WITH ENGINEERED FEATURES ===\n",
    "X_val_tt = tt.tuplefy(X_val_scaled, (y_dur_val, y_evt_val))\n",
    "X_test_tt = tt.tuplefy(X_test_scaled, (y_dur_test, y_evt_test))\n",
    "\n",
    "net = tt.practical.MLPVanilla(in_features=X_train_scaled.shape[1], num_nodes=[32],\n",
    "                              out_features=1, batch_norm=True, dropout=0.1)\n",
    "model = PycoxCoxPH(net, tt.optim.Adam)\n",
    "model.optimizer.set_lr(0.001)\n",
    "model.fit(X_train_scaled, (y_dur_train, y_evt_train), batch_size=256, epochs=200,\n",
    "          val_data=X_val_tt, verbose=True)\n",
    "model.compute_baseline_hazards()\n",
    "\n",
    "surv = model.predict_surv_df(X_test_scaled)\n",
    "ev = EvalSurv(surv, y_dur_test, y_evt_test, censor_surv='km')\n",
    "print(f\"\\nC-index on test set after feature engineering (PyCox): {ev.concordance_td():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d70d9-bc0e-4bd9-a2db-600f0cba365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 9: COMPARE BASELINE AND ENGINEERED APPROACHES ===\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "# Calculate baseline c-index\n",
    "X_test_base = pd.DataFrame(X_test_scaled, columns=selected_feature_names).drop(columns=to_drop)\n",
    "test_base = X_test_base.copy()\n",
    "test_base['duration'] = y_dur_test\n",
    "test_base['event'] = y_evt_test\n",
    "baseline_c_index = concordance_index(\n",
    "    test_base['duration'], -cph_base.predict_partial_hazard(test_base), test_base['event']\n",
    ")\n",
    "\n",
    "# Get PyCox c-index from earlier\n",
    "engineered_c_index = ev.concordance_td()\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(['Baseline (lifelines)', 'Engineered (PyCox)'],\n",
    "               [baseline_c_index, engineered_c_index], color=['skyblue', 'salmon'])\n",
    "plt.ylabel(\"C-index\")\n",
    "plt.title(\"Model Comparison: Baseline vs Feature Engineered\")\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.01, f\"{yval:.3f}\",\n",
    "             ha='center', va='bottom')\n",
    "plt.ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Model_comparison:baseline_vs_feature_engineered_trend.jpg\", dpi=300)\n",
    "print(\"Plot saved as: Model_comparison:baseline_vs_feature_engineered_trend.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805919b-f107-44fb-baf7-760504e15177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 10: FUNCTION TO EVALUATE C-INDEX BY FEATURE COUNT ===\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_feature_counts(X_train_selected, X_val_selected, X_test_selected,\n",
    "                            y_dur_train, y_evt_train, y_dur_val, y_evt_val,\n",
    "                            y_dur_test, y_evt_test,\n",
    "                            selected_feature_names, counts=[5, 10, 15, 20, 25, 30, 35, 40, 45, 50]):\n",
    "    results = []\n",
    "    print(\"Evaluating models with increasing feature counts:\\n\")\n",
    "    for k in tqdm(counts, desc=\"Overall progress\"):\n",
    "        print(f\"\\n--- Running model with top {k} features ---\")\n",
    "\n",
    "        # Select top-k features\n",
    "        feat_k = selected_feature_names[:k]\n",
    "        idxs = [list(selected_feature_names).index(f) for f in feat_k]\n",
    "\n",
    "        X_train_k = X_train_selected[:, idxs].astype('float32')\n",
    "        X_val_k = X_val_selected[:, idxs].astype('float32')\n",
    "        X_test_k = X_test_selected[:, idxs].astype('float32')\n",
    "\n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_train_k = scaler.fit_transform(X_train_k).astype('float32')\n",
    "        X_val_k = scaler.transform(X_val_k).astype('float32')\n",
    "        X_test_k = scaler.transform(X_test_k).astype('float32')\n",
    "\n",
    "        # Build and train PyCox model\n",
    "        net = tt.practical.MLPVanilla(in_features=X_train_k.shape[1], num_nodes=[32],\n",
    "                                      out_features=1, batch_norm=True, dropout=0.1)\n",
    "        model = PycoxCoxPH(net, tt.optim.Adam)\n",
    "        model.optimizer.set_lr(0.001)\n",
    "        val_data = tt.tuplefy(X_val_k, (y_dur_val, y_evt_val))\n",
    "        model.fit(X_train_k, (y_dur_train, y_evt_train), batch_size=256, epochs=100,\n",
    "                  val_data=val_data, verbose=False)\n",
    "        model.compute_baseline_hazards()\n",
    "\n",
    "        # Evaluate\n",
    "        surv = model.predict_surv_df(X_test_k)\n",
    "        ev = EvalSurv(surv, y_dur_test, y_evt_test, censor_surv='km')\n",
    "        c_index = ev.concordance_td()\n",
    "        results.append((k, c_index))\n",
    "\n",
    "    return pd.DataFrame(results, columns=['n_features', 'c_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaae35e-f48f-4de9-8cd3-77a5d8f77394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STEP 11: RUN ANALYSIS AND PLOT ===\n",
    "results_df = evaluate_feature_counts(\n",
    "    X_train_selected, X_val_selected, X_test_selected,\n",
    "    y_dur_train, y_evt_train, y_dur_val, y_evt_val,\n",
    "    y_dur_test, y_evt_test,\n",
    "    selected_feature_names\n",
    ")\n",
    "\n",
    "# Plot c-index vs. number of features\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(results_df['n_features'], results_df['c_index'], marker='o', linestyle='-')\n",
    "plt.xlabel(\"Number of Features Used\")\n",
    "plt.ylabel(\"C-index on Test Set\")\n",
    "plt.title(\"Impact of Number of Features on Model Performance\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Cox_impact_number_of_features_on_performance_trend.jpg\", dpi=300)\n",
    "print(\"Plot saved as: Cox_impact_number_of_features_on_performance_trend.jpg\")\n",
    "plt.show()\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b732a-8e17-41f3-9c76-575fa2d8504c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
